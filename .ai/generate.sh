#!/usr/bin/env bash
# ============================================================================
# generate.sh - Multi-platform configuration generator
# ============================================================================
# Generates platform-specific configuration files from .ai/skills/*.yaml
#
# Supported platforms:
#   - AGENTS.md (standard)
#   - CLAUDE.md (Claude Code)
#   - .claude/agents/*.md (Claude Code subagents)
#   - .cursorrules (Cursor)
#   - .continuerc.json (Continue.dev)
#   - .aider.conf.yml (Aider)
#   - ollama/Modelfile.* (Ollama)
#   - .opencode/agents/*.md (OpenCode)
#   - .codex/agents/*.md (Codex CLI)
#
# Usage:
#   ./generate.sh [OPTIONS]
#
# Options:
#   --force       Force regeneration even if VERSION unchanged
#   --check       Check if regeneration is needed (exit 1 if yes)
#   --check-docs  Check bilingual documentation sync (Phase 3.1)
#   --dry-run     Show what would be generated without writing
#   --verbose     Show detailed output
#   --help        Show this help message
#
# ============================================================================

set -euo pipefail

# ----------------------------------------------------------------------------
# Configuration
# ----------------------------------------------------------------------------
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
readonly SKILLS_DIR="${SCRIPT_DIR}/skills"
readonly VERSION_FILE="${SCRIPT_DIR}/VERSION"
readonly GENERATED_MARKER="Auto-generated by generate.sh"

# Platform output paths
readonly AGENTS_MD="${PROJECT_ROOT}/AGENTS.md"
readonly CLAUDE_MD="${PROJECT_ROOT}/CLAUDE.md"
readonly CLAUDE_AGENTS_DIR="${PROJECT_ROOT}/.claude/agents"
readonly CURSOR_RULES="${PROJECT_ROOT}/.cursorrules"
readonly CURSOR_HOOKS="${PROJECT_ROOT}/.cursor/hooks.json"
readonly CONTINUE_RC="${PROJECT_ROOT}/.continuerc.json"
readonly AIDER_CONF="${PROJECT_ROOT}/.aider.conf.yml"
readonly OLLAMA_DIR="${PROJECT_ROOT}/ollama"
readonly OPENCODE_AGENTS_DIR="${PROJECT_ROOT}/.opencode/agents"
readonly OPENCODE_HOOKS_DIR="${PROJECT_ROOT}/.opencode/hooks"
readonly CODEX_AGENTS_DIR="${PROJECT_ROOT}/.codex/agents"
readonly CODEX_CONFIG="${PROJECT_ROOT}/codex.toml"
readonly HOOKS_FILE="${SCRIPT_DIR}/hooks/hooks.yaml"
readonly CLAUDE_SETTINGS="${PROJECT_ROOT}/.claude/settings.json"
readonly MEMORY_YAML="${PROJECT_ROOT}/prompts/fr/metametaprompts/data/memory/MEMORY.yaml"
readonly MEMORY_MD="${SCRIPT_DIR}/MEMORY.md"

# Skills cache (loaded once, used by all generators)
SKILLS_CACHE=""

# Data source paths (source of truth)
readonly DATA_DIR="${PROJECT_ROOT}/prompts/fr/metametaprompts/data"
readonly DATA_HOOKS_INTERNAL="${DATA_DIR}/hooks/internal"
readonly DATA_HOOKS_EXTERNAL="${DATA_DIR}/hooks/external"
readonly DATA_SKILLS_INTERNAL="${DATA_DIR}/skills/internal"
readonly DATA_SKILLS_EXTERNAL="${DATA_DIR}/skills/external"
readonly DATA_COMMANDS_INTERNAL="${DATA_DIR}/commands/internal"
readonly DATA_COMMANDS_EXTERNAL="${DATA_DIR}/commands/external"
readonly MANIFEST_FILE="${DATA_DIR}/manifest.yaml"

# Options
FORCE=false
CHECK_ONLY=false
CHECK_DOCS=false
DRY_RUN=false
VERBOSE=false

# Colors (disabled if not a terminal)
if [[ -t 1 ]]; then
    readonly RED='\033[0;31m'
    readonly GREEN='\033[0;32m'
    readonly YELLOW='\033[0;33m'
    readonly BLUE='\033[0;34m'
    readonly NC='\033[0m' # No Color
else
    readonly RED=''
    readonly GREEN=''
    readonly YELLOW=''
    readonly BLUE=''
    readonly NC=''
fi

# ----------------------------------------------------------------------------
# Utility functions
# ----------------------------------------------------------------------------

log_info() {
    echo -e "${BLUE}[INFO]${NC} $*"
}

log_success() {
    echo -e "${GREEN}[OK]${NC} $*"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $*" >&2
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $*" >&2
}

log_verbose() {
    if [[ "${VERBOSE}" == "true" ]]; then
        echo -e "${BLUE}[DEBUG]${NC} $*"
    fi
}

show_help() {
    head -30 "${BASH_SOURCE[0]}" | tail -25 | sed 's/^# //' | sed 's/^#//'
}

# Check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Create directory if it doesn't exist
ensure_dir() {
    local dir="$1"
    if [[ ! -d "${dir}" ]]; then
        if [[ "${DRY_RUN}" == "true" ]]; then
            log_info "Would create directory: ${dir}"
        else
            mkdir -p "${dir}"
            log_verbose "Created directory: ${dir}"
        fi
    fi
}

# Write file with dry-run support
write_file() {
    local path="$1"
    local content="$2"

    if [[ "${DRY_RUN}" == "true" ]]; then
        log_info "Would write: ${path}"
        if [[ "${VERBOSE}" == "true" ]]; then
            echo "--- Content preview (first 20 lines) ---"
            echo "${content}" | head -20
            echo "---"
        fi
    else
        echo "${content}" > "${path}"
        log_verbose "Wrote: ${path}"
    fi
}

# ----------------------------------------------------------------------------
# Manifest validation (Phase 1.2 refactoring)
# ----------------------------------------------------------------------------

# Validate manifest integrity hashes
# Returns 0 if all hashes match, 1 if mismatches found
validate_manifest() {
    if [[ ! -f "${MANIFEST_FILE}" ]]; then
        log_verbose "No manifest file found, skipping validation"
        return 0
    fi

    log_verbose "Validating manifest integrity..."
    local mismatches=0

    # Check if we have yq for proper YAML parsing
    if command_exists yq; then
        # Use yq to extract integrity entries
        local entries
        entries=$(yq eval '.integrity | to_entries | .[] | "\(.key)|\(.value.hash)"' "${MANIFEST_FILE}" 2>/dev/null)

        while IFS='|' read -r file expected_hash; do
            if [[ -z "${file}" ]]; then
                continue
            fi

            local full_path="${DATA_DIR}/${file}"
            if [[ ! -f "${full_path}" ]]; then
                log_warn "Manifest file missing: ${file}"
                ((mismatches++))
                continue
            fi

            # Extract just the hash value (remove sha256: prefix if present)
            expected_hash="${expected_hash#sha256:}"

            # Compute actual hash
            local actual_hash
            if command_exists sha256sum; then
                actual_hash=$(sha256sum "${full_path}" | cut -d' ' -f1)
            elif command_exists shasum; then
                actual_hash=$(shasum -a 256 "${full_path}" | cut -d' ' -f1)
            else
                log_verbose "No SHA256 tool available, skipping hash check"
                return 0
            fi

            if [[ "${actual_hash}" != "${expected_hash}" ]]; then
                log_warn "Integrity mismatch: ${file}"
                log_verbose "  Expected: ${expected_hash}"
                log_verbose "  Actual:   ${actual_hash}"
                ((mismatches++))
            else
                log_verbose "Integrity OK: ${file}"
            fi
        done <<< "${entries}"
    else
        log_verbose "yq not available, skipping manifest validation"
        return 0
    fi

    if [[ ${mismatches} -gt 0 ]]; then
        log_warn "Found ${mismatches} integrity mismatch(es)"
        return 1
    fi

    log_verbose "All manifest integrity checks passed"
    return 0
}

# ----------------------------------------------------------------------------
# Documentation sync check (Phase 3.1 refactoring)
# ----------------------------------------------------------------------------

# Check if bilingual documentation is in sync
# Returns 0 if all docs are synced, 1 if mismatches found
check_docs_sync() {
    local docs_en="${PROJECT_ROOT}/docs/en"
    local docs_fr="${PROJECT_ROOT}/docs/fr"
    local mismatches=0

    if [[ ! -d "${docs_en}" ]] || [[ ! -d "${docs_fr}" ]]; then
        log_verbose "Documentation directories not found, skipping sync check"
        return 0
    fi

    log_verbose "Checking bilingual documentation sync..."

    # Check for missing French translations
    for en_doc in "${docs_en}"/*.md; do
        [[ ! -f "${en_doc}" ]] && continue

        local basename
        basename=$(basename "${en_doc}")
        local fr_doc="${docs_fr}/${basename}"

        if [[ ! -f "${fr_doc}" ]]; then
            log_warn "Missing FR translation: docs/fr/${basename}"
            ((mismatches++))
        else
            # Compare last modification times
            local en_mtime fr_mtime
            en_mtime=$(stat -c %Y "${en_doc}" 2>/dev/null || stat -f %m "${en_doc}" 2>/dev/null)
            fr_mtime=$(stat -c %Y "${fr_doc}" 2>/dev/null || stat -f %m "${fr_doc}" 2>/dev/null)

            if [[ -n "${en_mtime}" && -n "${fr_mtime}" ]]; then
                # If EN is more than 1 day newer than FR, warn
                local diff=$((en_mtime - fr_mtime))
                if [[ ${diff} -gt 86400 ]]; then
                    log_verbose "Possible translation drift: ${basename} (EN is newer)"
                fi
            fi
        fi
    done

    # Check for orphan French docs
    for fr_doc in "${docs_fr}"/*.md; do
        [[ ! -f "${fr_doc}" ]] && continue

        local basename
        basename=$(basename "${fr_doc}")
        local en_doc="${docs_en}/${basename}"

        if [[ ! -f "${en_doc}" ]]; then
            log_warn "Orphan FR doc (no EN source): docs/fr/${basename}"
            ((mismatches++))
        fi
    done

    if [[ ${mismatches} -gt 0 ]]; then
        log_warn "Found ${mismatches} documentation sync issue(s)"
        return 1
    fi

    log_verbose "All documentation files in sync"
    return 0
}

# ----------------------------------------------------------------------------
# YAML parsing using yq (KISS principle)
# ----------------------------------------------------------------------------
# Requires: yq (kislyuk/yq wrapper for jq)
# Install: pip install yq
# ----------------------------------------------------------------------------

# Extract a simple value from YAML
# Usage: yaml_get "file.yaml" "key"
yaml_get() {
    local file="$1"
    local key="$2"
    yq -r ".${key} // empty" "${file}" 2>/dev/null
}

# Extract multiline/nested value from YAML
# Usage: yaml_get_block "file.yaml" "instructions.role"
yaml_get_block() {
    local file="$1"
    local key="$2"
    yq -r ".${key} // empty" "${file}" 2>/dev/null
}

# Get list of items from YAML array
# Usage: yaml_get_list "file.yaml" "tags"
yaml_get_list() {
    local file="$1"
    local key="$2"
    yq -r ".${key}[]? // empty" "${file}" 2>/dev/null
}

# Load all skills into a JSON cache (called once at startup)
# This replaces 480+ yq calls with a single pass
load_skills_cache() {
    if [[ -n "${SKILLS_CACHE}" ]]; then
        return 0  # Already loaded
    fi

    log_verbose "Loading skills cache..."

    local skill_files
    skill_files=$(find "${SKILLS_DIR}" -name "*.yaml" -type f ! -name "_*" | sort)

    if [[ -z "${skill_files}" ]]; then
        SKILLS_CACHE="[]"
        return 0
    fi

    # Merge all skill files into a single JSON array with one yq call
    # shellcheck disable=SC2086
    SKILLS_CACHE=$(yq -s '[.[] | select(. != null)]' ${skill_files} 2>/dev/null || echo "[]")

    local count
    count=$(echo "${SKILLS_CACHE}" | jq 'length')
    log_verbose "Loaded ${count} skills into cache"
}

# Get skill field from cache
# Usage: skill_get "skill-name" "field"
skill_get() {
    local name="$1"
    local field="$2"
    echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" --arg field "${field}" \
        '.[] | select(.name == $name) | .[$field] // empty'
}

# Iterate over all skills in cache
# Usage: for_each_skill "jq_expression"
# Example: for_each_skill '.name + ": " + .description'
for_each_skill() {
    local expr="$1"
    echo "${SKILLS_CACHE}" | jq -r ".[] | ${expr}"
}

# Get all skill names from cache
get_skill_names() {
    echo "${SKILLS_CACHE}" | jq -r '.[].name | select(. != null and . != "")'
}

# ----------------------------------------------------------------------------
# Version checking
# ----------------------------------------------------------------------------

get_current_version() {
    if [[ -f "${VERSION_FILE}" ]]; then
        cat "${VERSION_FILE}"
    else
        echo "0.0.0"
    fi
}

compute_skills_hash() {
    # Compute a hash of all skill files to detect changes
    if command_exists md5sum; then
        find "${SKILLS_DIR}" -name "*.yaml" -type f ! -name "_*" -exec cat {} \; 2>/dev/null | md5sum | cut -d' ' -f1
    elif command_exists md5; then
        find "${SKILLS_DIR}" -name "*.yaml" -type f ! -name "_*" -exec cat {} \; 2>/dev/null | md5
    else
        # Fallback: use file modification times
        find "${SKILLS_DIR}" -name "*.yaml" -type f ! -name "_*" -printf '%T@\n' 2>/dev/null | sort | tail -1
    fi
}

needs_regeneration() {
    local current_version
    local skills_hash

    current_version=$(get_current_version)
    skills_hash=$(compute_skills_hash)

    # Check if version file contains the current hash
    if [[ "${current_version}" != *"${skills_hash}"* ]]; then
        return 0  # Needs regeneration
    fi
    return 1  # Up to date
}

# ----------------------------------------------------------------------------
# Sync functions (copy from data/ to .ai/)
# ----------------------------------------------------------------------------

# Sync skills from data/skills/internal + external to .ai/skills/
sync_skills() {
    log_info "Syncing skills from data/..."
    ensure_dir "${SKILLS_DIR}"

    # Copy internal skills
    if [[ -d "${DATA_SKILLS_INTERNAL}" ]]; then
        for file in "${DATA_SKILLS_INTERNAL}"/*.yaml; do
            if [[ -f "${file}" ]]; then
                cp "${file}" "${SKILLS_DIR}/"
            fi
        done
    fi

    # Copy external skills (if any)
    if [[ -d "${DATA_SKILLS_EXTERNAL}" ]]; then
        for file in "${DATA_SKILLS_EXTERNAL}"/*.yaml; do
            if [[ -f "${file}" ]]; then
                cp "${file}" "${SKILLS_DIR}/"
            fi
        done
    fi

    log_success "Synced skills"
}

# Sync hooks from data/hooks/internal + external to .ai/hooks/
sync_hooks() {
    log_info "Syncing hooks from data/..."
    ensure_dir "${SCRIPT_DIR}/hooks"

    local output_file="${SCRIPT_DIR}/hooks/hooks.yaml"
    local content="# ${GENERATED_MARKER}"$'\n'
    content+="# Merged from data/hooks/internal/ + external/"$'\n\n'

    # Append internal hooks (main hooks.yaml)
    if [[ -f "${DATA_HOOKS_INTERNAL}/hooks.yaml" ]]; then
        # Skip the first lines if they're comments and add the rest
        content+="# === Internal hooks ==="$'\n'
        cat "${DATA_HOOKS_INTERNAL}/hooks.yaml" >> /dev/null  # Validate file exists
        content+=$(cat "${DATA_HOOKS_INTERNAL}/hooks.yaml")
        content+=$'\n\n'
    fi

    # Append external hooks (individual YAML files)
    if [[ -d "${DATA_HOOKS_EXTERNAL}" ]]; then
        local has_external=false
        for file in "${DATA_HOOKS_EXTERNAL}"/*.yaml; do
            if [[ -f "${file}" && "$(basename "${file}")" != ".gitkeep" ]]; then
                if [[ "${has_external}" == "false" ]]; then
                    content+="# === External hooks ==="$'\n'
                    has_external=true
                fi
                content+="# From: $(basename "${file}")"$'\n'
                content+=$(cat "${file}")
                content+=$'\n\n'
            fi
        done
    fi

    if [[ "${DRY_RUN}" == "true" ]]; then
        log_info "Would write hooks to: ${output_file}"
    else
        echo "${content}" > "${output_file}"
    fi

    log_success "Synced hooks"
}

# Sync commands from data/commands/internal + external to .ai/commands/
sync_commands() {
    log_info "Syncing commands from data/..."
    local commands_dir="${SCRIPT_DIR}/commands"
    ensure_dir "${commands_dir}"

    # Copy internal commands
    if [[ -d "${DATA_COMMANDS_INTERNAL}" ]]; then
        for file in "${DATA_COMMANDS_INTERNAL}"/*.yaml; do
            if [[ -f "${file}" && "$(basename "${file}")" != ".gitkeep" ]]; then
                cp "${file}" "${commands_dir}/"
            fi
        done
    fi

    # Copy external commands (if any)
    if [[ -d "${DATA_COMMANDS_EXTERNAL}" ]]; then
        for file in "${DATA_COMMANDS_EXTERNAL}"/*.yaml; do
            if [[ -f "${file}" && "$(basename "${file}")" != ".gitkeep" ]]; then
                cp "${file}" "${commands_dir}/"
            fi
        done
    fi

    log_success "Synced commands"
}

# ----------------------------------------------------------------------------
# Generator functions
# ----------------------------------------------------------------------------

# Collect all skill files
get_skill_files() {
    find "${SKILLS_DIR}" -name "*.yaml" -type f ! -name "_*" | sort
}

# Generate the main AGENTS.md file
generate_agents_md() {
    log_info "Generating AGENTS.md..."

    local content
    content=$(cat << 'AGENTS_HEADER'
# Fundamental rules for AI agents

> This file follows the [AGENTS.md standard](https://agents.md/)
>
> __GENERATED_MARKER__ - Do not edit manually

## First mandatory action

1. **Read `.ai/MEMORY.md`** to load context and preferences
2. Run `.ai/generate.sh` if skills have been modified

## Rule 0: honesty

- Right to not know, to ask for clarification
- Never invent facts, never pretend
- Acknowledge uncertainty when present

## Rule 1: state of the art and consensus

- Consult official documentation before acting
- Search for solutions that have consensus on the internet
- Consult `.ai/sources.yaml` for reference URLs
- Prefer established patterns over novel approaches

## Rule 2: directed development

Order: specification -> documentation -> tests -> code -> refactoring

## Rule 3: security

- Never expose secrets (API keys, tokens, credentials)
- Principle of least privilege
- Validate inputs, escape outputs

## Rule 4: DRY and KISS

- Single source of truth (`prompts/fr/metametaprompts/data/`)
- Keep things simple
- Decompose into atomic tasks

## Rule 5: todo list

Format: `[ ]` to do, `[x]` done, `[~]` in progress, `[!]` blocked

## Rule 6: file organization

- `tmp/` for temporary files (gitignored)
- Never temporary files at root

## Rule 7: agent management

- Signal which agents are used: "Agent(s): [list]"
- AGENTS.md rules prevail over skill instructions

## Rule 8: self-improvement

- Propose updates if better practices detected
- Signal if instructions are obsolete

## Rule 9: checklist before commit

- [ ] `generate.sh` executed if skills modified
- [ ] `prompt-validator` passed if prompts modified
- [ ] `inclusivity-reviewer` passed if FR content modified
- [ ] `translator` sync check if docs modified
- [ ] `link-checker` passed if markdown files modified
- [ ] `memory-keeper` invoked if important decisions made

## Rule 10: writing conventions and inclusivity

### Inclusive writing (French)

- Middle dot (¬∑): expert¬∑e, utilisateur¬∑ice
- Epicene forms when possible
- Avoid ableist language

### Modern terminology

| Legacy | Modern |
|--------|--------|
| master/slave | primary/replica |
| whitelist/blacklist | allowlist/blocklist |
| master branch | main branch |

## Rule 11: persistent memory

- Read `.ai/MEMORY.md` at session start
- Update via `memory-keeper` after important decisions

## Rule 12: language

- Code: English
- Documentation: English (main) with French translation
- Cross-reference links between EN/FR docs

## Rule 13: version check

At session start, if this prompt has a META block:

1. Read \`source_url\` and \`version\` from META
2. Fetch source (if web access available)
3. Compare local version with remote version
4. If remote is newer: inform user, show changelog, propose update
5. If same or no web access: continue normally

## Rule 14: end-of-response summary

At the end of EACH significant response, include a visual summary showing:

1. **Skills used** in this response (with ‚úÖ/‚ùå status)
2. **Active workflow** if any
3. **Pending tasks** from todo list
4. **Commands available** reminder

Format example:
\`\`\`
---
üìä **Session Summary**
Skills: data-sync ‚úÖ | memory-keeper ‚úÖ | prompt-engineer ‚ùå
Workflow: normal
Tasks: 2 completed, 1 pending
\`\`\`

This is MANDATORY for user visibility. Do NOT rely on Stop hooks for this.

---

## Available skills

AGENTS_HEADER
)
    # Replace placeholder with actual marker
    content="${content//__GENERATED_MARKER__/${GENERATED_MARKER}}"

    # Add skill list from cache (single jq call)
    local skill_rows
    skill_rows=$(for_each_skill 'select(.name != null and .name != "") | "| " + .name + " | " + (.description // "No description") + " | " + (.category // "other") + " |"')
    content+=$'\n'"${skill_rows}"

    # Add table header before skills
    content=$(echo "${content}" | sed '/^## Available skills$/a\
\
| Skill | Description | Category |\
|-------|-------------|----------|')

    content+=$'\n\n'"---"$'\n\n'"*${GENERATED_MARKER}*"

    local agents_dir
    agents_dir=$(dirname "${AGENTS_MD}")
    ensure_dir "${agents_dir}"
    write_file "${AGENTS_MD}" "${content}"
    log_success "Generated AGENTS.md"
}

# Generate CLAUDE.md pointer file
generate_claude_md() {
    log_info "Generating CLAUDE.md..."

    local content
    content=$(cat << EOF
# Claude Code configuration

> See [AGENTS.md](./AGENTS.md) for the complete rules.
>
> ${GENERATED_MARKER}

This file exists for backward compatibility with Claude Code.
All configuration is centralized in AGENTS.md.

## Quick start

\`\`\`bash
# First action at session start
cat .ai/MEMORY.md

# If skills were modified
.ai/generate.sh
\`\`\`

## Available skills

EOF
)

    # Add skill list from cache (single jq call)
    local skill_list
    skill_list=$(for_each_skill 'select(.name != null and .name != "") | "- **" + .name + "**: " + (.description // "No description")')
    content+="${skill_list}"$'\n'

    write_file "${CLAUDE_MD}" "${content}"
    log_success "Generated CLAUDE.md"
}

# Generate Claude Code subagent files
generate_claude_agents() {
    log_info "Generating Claude Code subagents..."

    ensure_dir "${CLAUDE_AGENTS_DIR}"

    # Generate all agent files using cache (process each skill)
    local name
    for name in $(get_skill_names); do
        local agent_file="${CLAUDE_AGENTS_DIR}/${name}.md"

        # Extract all fields for this skill in one jq call
        local skill_data
        skill_data=$(echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" '
            .[] | select(.name == $name) | {
                description: (.description // "No description"),
                instructions: (.instructions // ""),
                constraints: (.constraints // [])
            }
        ')

        local description instructions constraints_json
        description=$(echo "${skill_data}" | jq -r '.description')
        instructions=$(echo "${skill_data}" | jq -r '.instructions')
        constraints_json=$(echo "${skill_data}" | jq -r '.constraints[]? // empty')

        local content="# ${name}"$'\n\n'
        content+="${description}"$'\n\n'

        if [[ -n "${instructions}" ]]; then
            content+="## Instructions"$'\n\n'
            content+="${instructions}"$'\n'
        fi

        if [[ -n "${constraints_json}" ]]; then
            content+="## Constraints"$'\n\n'
            while IFS= read -r line; do
                [[ -n "${line}" ]] && content+="- ${line}"$'\n'
            done <<< "${constraints_json}"
        fi

        content+=$'\n'"---"$'\n'"*${GENERATED_MARKER}*"$'\n'

        write_file "${agent_file}" "${content}"
    done

    log_success "Generated Claude Code subagents"
}

# Generate .cursorrules file
generate_cursorrules() {
    log_info "Generating .cursorrules..."

    local content="# Cursor Rules"$'\n'
    content+="# ${GENERATED_MARKER}"$'\n\n'
    content+="## General rules"$'\n\n'
    content+="- Read .ai/MEMORY.md at session start"$'\n'
    content+="- Follow AGENTS.md guidelines"$'\n'
    content+="- Use inclusive writing for French content"$'\n\n'
    content+="## Available skills"$'\n\n'

    # Generate skill sections from cache
    local name
    for name in $(get_skill_names); do
        local skill_data
        skill_data=$(echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" '
            .[] | select(.name == $name) | {
                description: (.description // "No description"),
                instructions: (.instructions // "")
            }
        ')

        local description instructions
        description=$(echo "${skill_data}" | jq -r '.description')
        instructions=$(echo "${skill_data}" | jq -r '.instructions')

        content+="### ${name}"$'\n\n'
        content+="${description}"$'\n\n'

        if [[ -n "${instructions}" ]]; then
            content+="${instructions}"$'\n'
        fi

        content+=$'\n'
    done

    write_file "${CURSOR_RULES}" "${content}"
    log_success "Generated .cursorrules"
}

# Generate Cursor hooks configuration
# Cursor hooks format: https://cursor.com/docs/agent/hooks
# Events: beforeSubmitPrompt, beforeShellExecution, beforeMCPExecution, beforeReadFile, afterFileEdit, stop
generate_cursor_hooks() {
    log_info "Generating Cursor hooks..."

    if [[ ! -f "${HOOKS_FILE}" ]]; then
        log_warn "Hooks file not found: ${HOOKS_FILE}"
        log_warn "Skipping Cursor hooks generation"
        return 0
    fi

    ensure_dir "$(dirname "${CURSOR_HOOKS}")"

    # Map Claude Code events to Cursor events
    # Claude Code -> Cursor:
    #   UserPromptSubmit -> beforeSubmitPrompt
    #   PreToolUse (Bash) -> beforeShellExecution
    #   PreToolUse (Read) -> beforeReadFile
    #   PostToolUse (Write/Edit) -> afterFileEdit
    #   Stop -> stop

    local hooks_json='{"$schema":"https://unpkg.com/cursor-hooks@latest/schema/hooks.schema.json","version":1,"hooks":{'
    local first_event=true

    # beforeSubmitPrompt - from UserPromptSubmit
    local beforeSubmit=""
    beforeSubmit=$(grep -A 50 "^UserPromptSubmit:" "${HOOKS_FILE}" 2>/dev/null | grep -E "command:" | head -1 | sed 's/.*command:[[:space:]]*//' | sed 's/^|.*//' | tr -d '"' | head -c 200)
    if [[ -n "${beforeSubmit}" && "${beforeSubmit}" != "|" ]]; then
        hooks_json+='"beforeSubmitPrompt":[{"command":"echo \"üìã Cursor: Prompt submitted\""}]'
        first_event=false
    fi

    # beforeShellExecution - from PreToolUse Bash
    if grep -q 'matcher:.*Bash' "${HOOKS_FILE}" 2>/dev/null; then
        [[ "${first_event}" != "true" ]] && hooks_json+=","
        hooks_json+='"beforeShellExecution":[{"command":"echo \"üîí Cursor: Shell execution check\""}]'
        first_event=false
    fi

    # afterFileEdit - from PostToolUse Write
    if grep -q 'matcher:.*Write' "${HOOKS_FILE}" 2>/dev/null; then
        [[ "${first_event}" != "true" ]] && hooks_json+=","
        hooks_json+='"afterFileEdit":[{"command":"echo \"üìù Cursor: File edited\""}]'
        first_event=false
    fi

    # stop - from Stop event
    if grep -q "^Stop:" "${HOOKS_FILE}" 2>/dev/null; then
        [[ "${first_event}" != "true" ]] && hooks_json+=","
        hooks_json+='"stop":[{"command":"echo \"‚úÖ Cursor: Task completed\""}]'
        first_event=false
    fi

    hooks_json+='}}'

    # Format JSON if jq is available
    if command_exists jq; then
        hooks_json=$(echo "${hooks_json}" | jq '.' 2>/dev/null) || true
    fi

    write_file "${CURSOR_HOOKS}" "${hooks_json}"
    log_success "Generated Cursor hooks"
}

# Generate OpenCode hooks scripts
# OpenCode uses shell scripts in .opencode/hooks/ directory
generate_opencode_hooks() {
    log_info "Generating OpenCode hooks..."

    if [[ ! -f "${HOOKS_FILE}" ]]; then
        log_warn "Hooks file not found: ${HOOKS_FILE}"
        log_warn "Skipping OpenCode hooks generation"
        return 0
    fi

    ensure_dir "${OPENCODE_HOOKS_DIR}"

    # Create a general hook script for OpenCode
    local hook_script='#!/usr/bin/env bash
# '"${GENERATED_MARKER}"'
# OpenCode hook script - runs on various lifecycle events
# Place in .opencode/hooks/ and configure in oh-my-opencode.json

HOOK_EVENT="${1:-unknown}"

case "$HOOK_EVENT" in
    "chat.message")
        echo "üìã [OpenCode] Message received"
        ;;
    "session.create")
        echo "üöÄ [OpenCode] Session started"
        cat .ai/MEMORY.md 2>/dev/null || echo "No memory file found"
        ;;
    "session.error")
        echo "‚ùå [OpenCode] Session error"
        ;;
    *)
        echo "‚ÑπÔ∏è [OpenCode] Event: $HOOK_EVENT"
        ;;
esac
'

    write_file "${OPENCODE_HOOKS_DIR}/lifecycle.sh" "${hook_script}"

    # Make executable
    if [[ "${DRY_RUN}" != "true" ]]; then
        chmod +x "${OPENCODE_HOOKS_DIR}/lifecycle.sh" 2>/dev/null || true
    fi

    log_success "Generated OpenCode hooks"
}

# Generate Claude Code custom commands from commands.yaml
generate_claude_commands() {
    log_info "Generating Claude Code commands..."

    local commands_dir="${PROJECT_ROOT}/.claude/commands"
    ensure_dir "${commands_dir}"

    local commands_file="${SCRIPT_DIR}/commands/commands.yaml"
    if [[ ! -f "${commands_file}" ]]; then
        log_warn "No commands.yaml found, skipping"
        return 0
    fi

    if ! command_exists yq; then
        log_error "yq is required for commands generation. Install with: pip install yq"
        return 1
    fi

    # Get all command keys (exclude metadata keys)
    local cmd_keys
    cmd_keys=$(yq -r 'keys | .[] | select(. != "_meta" and . != "version" and . != "updated")' "${commands_file}")

    for cmd_name in ${cmd_keys}; do
        # Skip if not for Claude platform
        local for_claude
        for_claude=$(yq -r ".\"${cmd_name}\".platforms.claude // true" "${commands_file}")
        [[ "${for_claude}" != "true" ]] && continue

        local desc command skill output
        desc=$(yq -r ".\"${cmd_name}\".description // \"No description\"" "${commands_file}")
        command=$(yq -r ".\"${cmd_name}\".command // empty" "${commands_file}")
        skill=$(yq -r ".\"${cmd_name}\".skill // empty" "${commands_file}")
        output=$(yq -r ".\"${cmd_name}\".output // empty" "${commands_file}")

        # Build markdown content
        local content="# /${cmd_name}"$'\n\n'
        content+="${desc}"$'\n\n'

        if [[ -n "${command}" ]]; then
            content+="Run: \`${command}\`"$'\n'
        elif [[ -n "${skill}" ]]; then
            content+="Invoke skill: \`@${skill}\`"$'\n'
        fi

        if [[ -n "${output}" ]]; then
            content+=$'\n'"${output}"
        fi

        echo "${content}" > "${commands_dir}/${cmd_name}.md"
    done

    log_success "Generated Claude Code commands"
}

# Generate Codex CLI configuration with notify
# Codex uses config.toml with notify option
generate_codex_config() {
    log_info "Generating Codex config..."

    local content='# '"${GENERATED_MARKER}"'
# Codex CLI configuration
# https://developers.openai.com/codex/config-reference/

[agent]
# Model configuration
model = "gpt-4"

[notifications]
# Notify on agent turn complete
# Currently the only supported event
notify = ["bash", "-c", "echo \"‚úÖ [Codex] Agent turn completed\""]

[context]
# Load project memory
auto_context = [".ai/MEMORY.md", "AGENTS.md"]

[sandbox]
# Enable sandbox mode for safety
enabled = true
'

    write_file "${CODEX_CONFIG}" "${content}"
    log_success "Generated Codex config"
}

# Generate .continuerc.json
generate_continuerc() {
    log_info "Generating .continuerc.json..."

    # Build skills JSON array using jq (single call)
    local skills_json
    skills_json=$(echo "${SKILLS_CACHE}" | jq '[.[] | select(.name != null and .name != "") | {name: .name, description: (.description // "No description")}]')

    local content
    content=$(jq -n --arg comment "${GENERATED_MARKER}" --argjson skills "${skills_json}" '{
        "_comment": $comment,
        "customCommands": $skills
    }')

    write_file "${CONTINUE_RC}" "${content}"
    log_success "Generated .continuerc.json"
}

# Generate .aider.conf.yml
generate_aider_conf() {
    log_info "Generating .aider.conf.yml..."

    local content="# ${GENERATED_MARKER}"$'\n\n'
    content+="# Aider configuration"$'\n'
    content+="# See: https://aider.chat/docs/config.html"$'\n\n'
    content+="read:"$'\n'
    content+="  - .ai/MEMORY.md"$'\n'
    content+="  - AGENTS.md"$'\n\n'
    content+="# Conventions from skills"$'\n'
    content+="conventions: |"$'\n'
    content+="  Follow AGENTS.md rules."$'\n'
    content+="  Use inclusive writing for French content."$'\n'
    content+="  Check .ai/MEMORY.md for project context."$'\n\n'
    content+="# Available skills:"$'\n'

    # Add skill comments from cache
    local skill_comments
    skill_comments=$(for_each_skill 'select(.name != null and .name != "") | "#   - " + .name + ": " + (.description // "No description")')
    content+="${skill_comments}"$'\n'

    write_file "${AIDER_CONF}" "${content}"
    log_success "Generated .aider.conf.yml"
}

# Generate Ollama Modelfiles
generate_ollama_modelfiles() {
    log_info "Generating Ollama Modelfiles..."

    ensure_dir "${OLLAMA_DIR}"

    local name
    for name in $(get_skill_names); do
        local skill_data
        skill_data=$(echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" '
            .[] | select(.name == $name) | {
                description: (.description // "No description"),
                instructions: (.instructions // "")
            }
        ')

        local description instructions
        description=$(echo "${skill_data}" | jq -r '.description')
        instructions=$(echo "${skill_data}" | jq -r '.instructions')

        local modelfile="${OLLAMA_DIR}/Modelfile.${name}"
        local content="# ${GENERATED_MARKER}"$'\n'
        content+="# Skill: ${name}"$'\n\n'
        content+="FROM llama3.2"$'\n\n'
        content+="PARAMETER temperature 0.3"$'\n'
        content+="PARAMETER num_ctx 4096"$'\n\n'
        content+="SYSTEM \"\"\""$'\n'
        content+="${description}"$'\n\n'

        if [[ -n "${instructions}" ]]; then
            content+="${instructions}"
        fi

        content+=$'\n'"\"\"\""$'\n'

        write_file "${modelfile}" "${content}"
    done

    log_success "Generated Ollama Modelfiles"
}

# Generate OpenCode agent files
generate_opencode_agents() {
    log_info "Generating OpenCode agents..."

    ensure_dir "${OPENCODE_AGENTS_DIR}"

    local name
    for name in $(get_skill_names); do
        local skill_data
        skill_data=$(echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" '
            .[] | select(.name == $name) | {
                description: (.description // "No description"),
                instructions: (.instructions // "")
            }
        ')

        local description instructions
        description=$(echo "${skill_data}" | jq -r '.description')
        instructions=$(echo "${skill_data}" | jq -r '.instructions')

        local agent_file="${OPENCODE_AGENTS_DIR}/${name}.md"
        local content="# ${name}"$'\n\n'
        content+="${description}"$'\n\n'

        if [[ -n "${instructions}" ]]; then
            content+="## Instructions"$'\n\n'
            content+="${instructions}"$'\n'
        fi

        content+=$'\n'"---"$'\n'"*${GENERATED_MARKER}*"$'\n'

        write_file "${agent_file}" "${content}"
    done

    log_success "Generated OpenCode agents"
}

# Generate Codex agent files
generate_codex_agents() {
    log_info "Generating Codex agents..."

    ensure_dir "${CODEX_AGENTS_DIR}"

    local name
    for name in $(get_skill_names); do
        local skill_data
        skill_data=$(echo "${SKILLS_CACHE}" | jq -r --arg name "${name}" '
            .[] | select(.name == $name) | {
                description: (.description // "No description"),
                instructions: (.instructions // "")
            }
        ')

        local description instructions
        description=$(echo "${skill_data}" | jq -r '.description')
        instructions=$(echo "${skill_data}" | jq -r '.instructions')

        local agent_file="${CODEX_AGENTS_DIR}/${name}.md"
        local content="# ${name}"$'\n\n'
        content+="${description}"$'\n\n'

        if [[ -n "${instructions}" ]]; then
            content+="## Instructions"$'\n\n'
            content+="${instructions}"$'\n'
        fi

        content+=$'\n'"---"$'\n'"*${GENERATED_MARKER}*"$'\n'

        write_file "${agent_file}" "${content}"
    done

    log_success "Generated Codex agents"
}

# Generate Claude Code hooks settings using yq
# Simplified version: 266 lines ‚Üí ~25 lines (KISS principle)
# Requires: yq (kislyuk/yq or mikefarah/yq)
generate_claude_hooks() {
    log_info "Generating Claude Code hooks..."

    if [[ ! -f "${HOOKS_FILE}" ]]; then
        log_warn "Hooks file not found: ${HOOKS_FILE}"
        log_warn "Skipping hooks generation"
        return 0
    fi

    if ! command_exists yq; then
        log_error "yq is required for hooks generation. Install with: pip install yq"
        return 1
    fi

    ensure_dir "$(dirname "${CLAUDE_SETTINGS}")"

    # Use yq to transform YAML to JSON (replaces 240+ lines of state machine)
    local hooks_json
    hooks_json=$(yq '
      # Filter enabled hooks and remove metadata fields
      def transform_hook:
        select(.enabled == true) |
        del(.name, .description, .enabled);

      {
        "_comment": "Auto-generated by generate.sh from .ai/hooks/hooks.yaml",
        "hooks": {
          "SessionStart": [.SessionStart[]? | transform_hook],
          "UserPromptSubmit": [.UserPromptSubmit[]? | transform_hook],
          "PreToolUse": [.PreToolUse[]? | transform_hook],
          "PostToolUse": [.PostToolUse[]? | transform_hook],
          "Stop": [.Stop[]? | transform_hook]
        }
      }
      # Remove empty event arrays
      | .hooks |= with_entries(select(.value | length > 0))
    ' "${HOOKS_FILE}" 2>/dev/null)

    if [[ -z "${hooks_json}" ]]; then
        log_error "Failed to parse hooks file with yq"
        return 1
    fi

    write_file "${CLAUDE_SETTINGS}" "${hooks_json}"
    log_success "Generated Claude Code hooks settings"
}

# Generate MEMORY.md from MEMORY.yaml
generate_memory_md() {
    log_info "Generating MEMORY.md..."

    if [[ ! -f "${MEMORY_YAML}" ]]; then
        log_warn "MEMORY.yaml not found: ${MEMORY_YAML}"
        return 0
    fi

    local content="# Project memory"$'\n\n'
    content+="> Persistent memory for AI agents. Read at session start, update via \`memory-keeper\`."$'\n'
    content+="> **Source of truth**: \`prompts/fr/metametaprompts/data/memory/MEMORY.yaml\`"$'\n\n'

    # Extract identity (using yq path notation)
    local name type created main_lang paradigm
    name=$(yaml_get "${MEMORY_YAML}" "identity.name")
    type=$(yaml_get "${MEMORY_YAML}" "identity.type")
    created=$(yaml_get "${MEMORY_YAML}" "identity.created")
    main_lang=$(yaml_get "${MEMORY_YAML}" "identity.main_language")
    paradigm=$(yaml_get "${MEMORY_YAML}" "identity.paradigm")

    content+="## Project identity"$'\n\n'
    content+="| Property | Value |"$'\n'
    content+="|----------|-------|"$'\n'
    content+="| Name | ${name:-Meta-prompt-LLM} |"$'\n'
    content+="| Type | ${type:-Prompt framework} |"$'\n'
    content+="| Created | ${created:-2026-01-31} |"$'\n'
    content+="| Main language | ${main_lang:-English} |"$'\n'
    content+="| Paradigm | ${paradigm:-Doc-driven} |"$'\n\n'

    # Description
    content+="## Description"$'\n\n'
    local desc
    desc=$(yaml_get_block "${MEMORY_YAML}" "description")
    if [[ -n "${desc}" ]]; then
        content+="${desc}"$'\n'
    fi

    # User preferences
    content+="## User preferences"$'\n\n'
    content+="| Preference | Value |"$'\n'
    content+="|------------|-------|"$'\n'
    local pref_lang pref_code inc_writing shell_std ai_cov summary
    pref_lang=$(yaml_get "${MEMORY_YAML}" "preferences.language_interface")
    pref_code=$(yaml_get "${MEMORY_YAML}" "preferences.language_code_docs")
    inc_writing=$(yaml_get "${MEMORY_YAML}" "preferences.inclusive_writing")
    shell_std=$(yaml_get "${MEMORY_YAML}" "preferences.shell_standard")
    ai_cov=$(yaml_get "${MEMORY_YAML}" "preferences.ai_tools_coverage")
    summary=$(yaml_get "${MEMORY_YAML}" "preferences.end_of_response_summary")
    content+="| Language (interface) | ${pref_lang:-French} |"$'\n'
    content+="| Language (code/docs) | ${pref_code:-English} |"$'\n'
    content+="| Inclusive writing | ${inc_writing:-true} |"$'\n'
    content+="| Shell standard | ${shell_std:-Bash} |"$'\n'
    content+="| AI tools coverage | ${ai_cov:-Maximum} |"$'\n'
    content+="| End-of-response summary | ${summary:-true} |"$'\n\n'

    # Available skills
    content+="## Available skills"$'\n\n'
    content+="| Skill | Purpose | Status |"$'\n'
    content+="|-------|---------|--------|"$'\n'

    # Add skill rows from cache
    local skill_rows
    skill_rows=$(for_each_skill 'select(.name != null and .name != "") | "| " + .name + " | " + (.description // "No description") + " | Active |"')
    content+="${skill_rows}"$'\n\n'

    # Notes section
    content+="## Notes"$'\n\n'
    content+="- All prompts must follow \`prompts/_TEMPLATE.md\`"$'\n'
    content+="- Run \`generate.sh\` after any skill modification"$'\n'
    content+="- French content must use inclusive writing"$'\n'
    content+="- **Source of truth**: \`prompts/fr/metametaprompts/data/\`"$'\n'
    content+="- **Generated files**: \`.ai/\` (never edit directly)"$'\n'
    content+="- Use \`@future-self\` in commits to leave notes for future sessions"$'\n\n'

    # Platform support matrix
    content+="## Platform Support Matrix"$'\n\n'
    content+="| Platform | Rating | Limitations |"$'\n'
    content+="|----------|--------|-------------|"$'\n'
    content+="| Claude Code | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | None - all 6 events + agent hooks |"$'\n'
    content+="| Cursor | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | No SessionStart, no agent hooks |"$'\n'
    content+="| OpenCode | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ | Requires oh-my-opencode plugin |"$'\n'
    content+="| Codex CLI | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ | Only notify on agent-turn-complete |"$'\n'
    content+="| Aider | ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ | No hooks, only auto_lint/test_cmd |"$'\n'
    content+="| Continue.dev | ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ | Data events only, no command hooks |"$'\n\n'

    # Footer
    local updated updated_by session
    updated=$(yaml_get "${MEMORY_YAML}" "updated")
    updated_by=$(yaml_get "${MEMORY_YAML}" "updated_by")
    session=$(yaml_get "${MEMORY_YAML}" "session")
    content+="---"$'\n\n'
    content+="*Last updated: ${updated:-unknown} by ${updated_by:-unknown} (session ${session:-unknown})*"$'\n'
    content+="*Generated from: prompts/fr/metametaprompts/data/memory/MEMORY.yaml*"$'\n'

    write_file "${MEMORY_MD}" "${content}"
    log_success "Generated MEMORY.md"
}

# Update VERSION file
update_version() {
    local skills_hash
    skills_hash=$(compute_skills_hash)
    local version="1.0.0-${skills_hash}"

    if [[ "${DRY_RUN}" == "true" ]]; then
        log_info "Would update VERSION to: ${version}"
    else
        echo "${version}" > "${VERSION_FILE}"
        log_success "Updated VERSION: ${version}"
    fi
}

# ----------------------------------------------------------------------------
# Main execution
# ----------------------------------------------------------------------------

main() {
    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --force)
                FORCE=true
                shift
                ;;
            --check)
                CHECK_ONLY=true
                shift
                ;;
            --check-docs)
                CHECK_DOCS=true
                shift
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                log_error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done

    log_info "Meta-prompt-LLM configuration generator"
    log_info "Project root: ${PROJECT_ROOT}"

    # Handle --check-docs flag (Phase 3.1)
    if [[ "${CHECK_DOCS}" == "true" ]]; then
        if check_docs_sync; then
            log_success "Documentation sync check passed"
            exit 0
        else
            log_error "Documentation sync check failed"
            exit 1
        fi
    fi

    # Check if skills directory exists
    if [[ ! -d "${SKILLS_DIR}" ]]; then
        log_error "Skills directory not found: ${SKILLS_DIR}"
        exit 1
    fi

    # Count skill files
    local skill_count
    skill_count=$(get_skill_files | wc -l)
    log_info "Found ${skill_count} skill files"

    if [[ "${skill_count}" -eq 0 ]]; then
        log_warn "No skill files found in ${SKILLS_DIR}"
        log_warn "Skipping generation"
        exit 0
    fi

    # Validate manifest integrity (Phase 1.2)
    if [[ "${VERBOSE}" == "true" ]]; then
        validate_manifest || log_warn "Manifest validation had warnings"
    fi

    # Check if regeneration is needed
    if [[ "${FORCE}" != "true" ]] && ! needs_regeneration; then
        log_success "Already up to date (use --force to regenerate)"
        if [[ "${CHECK_ONLY}" == "true" ]]; then
            exit 0
        fi
        return 0
    fi

    if [[ "${CHECK_ONLY}" == "true" ]]; then
        log_warn "Regeneration needed"
        exit 1
    fi

    # Sync from data/ source of truth
    sync_skills
    sync_hooks
    sync_commands

    # Load skills cache (one yq call instead of 480+)
    load_skills_cache

    # Run all generators
    generate_memory_md
    generate_agents_md
    generate_claude_md
    generate_claude_agents
    generate_claude_hooks
    generate_cursorrules
    generate_cursor_hooks
    generate_continuerc
    generate_aider_conf
    generate_ollama_modelfiles
    generate_opencode_agents
    generate_opencode_hooks
    generate_codex_agents
    generate_codex_config
    generate_claude_commands

    # Update version
    update_version

    log_success "Generation complete!"

    if [[ "${DRY_RUN}" == "true" ]]; then
        log_info "(Dry run - no files were written)"
    fi
}

main "$@"
